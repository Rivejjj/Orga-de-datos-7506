{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Organizaci&oacute;n de Datos</center>\n",
    "#### <center>C&aacute;tedra Ing. Rodriguez, Juan Manuel </center>\n",
    "\n",
    "## <center>Trabajo Práctico 2 : Propiedades en Venta</center>\n",
    "## <center>Parte 3</center>\n",
    "### <center> Grupo 22 </center>\n",
    "### <center> Integrantes: </center>\n",
    "##### <center> Federico Martin Forte,  Francisco Sobral,  Ian Klaus von der Heyde,  Juan Pablo Aschieri,  Joaquin Rivero  </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos y librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "viviendas_train=pd.read_csv('./TP1/Datasets/viviendas_caba_train.csv').copy()\n",
    "viviendas_test=pd.read_csv('./TP1/Datasets/viviendas_caba_test.csv').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "viviendas = pd.concat([viviendas_train, viviendas_test]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ensamble de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo los datos de entrenamiento y prueba de nuestro Random Forest\n",
    "\n",
    "y_train = pd.read_csv('./TP1/Datasets/y_train_property_type.csv').copy()\n",
    "y_test = pd.read_csv('./TP1/Datasets/y_test_property_type.csv').copy()\n",
    "\n",
    "x_train = pd.read_csv('./TP1/Datasets/x_train_property_type.csv').copy()\n",
    "x_test = pd.read_csv('./TP1/Datasets/x_test_property_type.csv').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting sobre modelos nuevos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a evaluar distintos clasificadores para ver cual me conviene para obtener mejores metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicciones con decision tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc = dtc.fit(x_train, y_train)\n",
    "y_pred_dtc = dtc.predict(x_test)\n",
    "\n",
    "\n",
    "# Predicciones con logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(x_train, y_train)\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "\n",
    "# Predicciones con naive bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(x_train, y_train)\n",
    "y_pred_gnb = gnb.predict(x_test)\n",
    "\n",
    "# Predicciones con modelo AdaBoost\n",
    "ada_boost_clf = AdaBoostClassifier()\n",
    "ada_boost_clf.fit(x_train, y_train)\n",
    "y_pred_ada = ada_boost_clf.predict(x_test)\n",
    "\n",
    "# Predicciones con modelo Random Forest\n",
    "rnd_clf = RandomForestClassifier()\n",
    "rnd_clf.fit(x_train, y_train)\n",
    "y_pred_rnd = rnd_clf.predict(x_test)\n",
    "\n",
    "# Predicciones con modelo KNN\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(x_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimo los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of decision tree classifier: 0.7051\n",
      "F1-score of support vector machine: 0.5468\n",
      "F1-score of naive bayes classifier: 0.3733\n",
      "F1-score of random forest classifier: 0.7455\n",
      "F1-score of KNN classifier: 0.6116\n",
      "F1-score of AdaBoost classifier: 0.5932\n"
     ]
    }
   ],
   "source": [
    "# evaluating the models based on their f-1 scores\n",
    "f1_dtc = f1_score(y_test, y_pred_dtc,average='weighted')\n",
    "f1_lr = f1_score(y_test, y_pred_lr,average='weighted')\n",
    "f1_gnb = f1_score(y_test, y_pred_gnb,average='weighted')\n",
    "f1_rnd = f1_score(y_test, y_pred_rnd,average='weighted')\n",
    "f1_knn = f1_score(y_test, y_pred_knn,average='weighted')\n",
    "f1_ada = f1_score(y_test, y_pred_ada,average='weighted')\n",
    "\n",
    "# print the f-1 scores\n",
    "print('F1-score of decision tree classifier: {}'.format(np.round(f1_dtc,4)))\n",
    "print('F1-score of support vector machine: {}'.format(np.round(f1_lr,4)))\n",
    "print('F1-score of naive bayes classifier: {}'.format(np.round(f1_gnb,4)))\n",
    "print('F1-score of random forest classifier: {}'.format(np.round(f1_rnd,4)))\n",
    "print('F1-score of KNN classifier: {}'.format(np.round(f1_knn,4)))\n",
    "print('F1-score of AdaBoost classifier: {}'.format(np.round(f1_ada,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca podemos ver que los mejores 3 modelos fueron los de Decision Tree Classifier, Random Forest Classifier y KNN. Procedo a realizar el Voting con dichos tres modelos. Para obtener mejores resultados, tambien voy a evaluar realizando una votacion de tipo Hard y una de tipo Soft y utilizar la que mejores resultados de."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo ensemble de Votación Hard\n",
    "vot_clf_h = VotingClassifier(estimators = [('dtc', dtc), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'hard')\n",
    "\n",
    "#Creo ensemble de Votación Soft\n",
    "vot_clf_s = VotingClassifier(estimators = [('dtc', dtc), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'soft')\n",
    "\n",
    "\n",
    "#Entreno ambos ensembles\n",
    "vot_clf_h.fit(x_train, y_train)\n",
    "vot_clf_s.fit(x_train, y_train)\n",
    "\n",
    "#Evaluo en conjunto de test\n",
    "pred_h = vot_clf_h.predict(x_test)\n",
    "pred_s = vot_clf_s.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS HARD VOTING:\n",
      "\n",
      "Accuracy Score: 0.7312123169681309\n",
      "F1-score: 0.7307880100119394\n",
      "Precision Score :  0.7317950183500754\n",
      "Recall Score : 0.7312123169681309\n",
      "\n",
      "RESULTADOS SOFT VOTING:\n",
      "\n",
      "Accuracy Score: 0.7263673557278209\n",
      "F1-score: 0.7257918025460124\n",
      "Precision Score:  0.7265844344077349\n",
      "Recall Score: 0.7263673557278209\n"
     ]
    }
   ],
   "source": [
    "#Calculo accuracy\n",
    "print(\"RESULTADOS HARD VOTING:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, pred_h)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, pred_h,average=\"weighted\")))\n",
    "print(\"Precision Score : \",precision_score(y_test,pred_h,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score :\" , recall_score(y_test, pred_h, pos_label='positive',average=\"weighted\"))\n",
    "\n",
    "print(\"\\nRESULTADOS SOFT VOTING:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, pred_s)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, pred_s,average=\"weighted\")))\n",
    "print(\"Precision Score: \",precision_score(y_test,pred_s,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score:\" , recall_score(y_test, pred_s, pos_label='positive',average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluimos que conviene utilizar el metodo de Hard voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting sobre nuestros modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo los modelos del TP1\n",
    "\n",
    "knn_clf = joblib.load('./TP1/Models/knn_mejor_performance')\n",
    "rnd_clf = joblib.load('./TP1/Models/rf_mejor_performance')\n",
    "dtc_clf = joblib.load('./TP1/Models/arbol_mejor_performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con modelo Knn\n",
    "y_pred_knn = knn_clf.predict(x_test)\n",
    "\n",
    "# Predicciones con modelo Random Forest\n",
    "y_pred_rnd = rnd_clf.predict(x_test)\n",
    "\n",
    "# Predicciones con modelo DTC\n",
    "y_pred_dtc = dtc_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTADOS K_nearest neighbors:\n",
      "\n",
      "Accuracy Score: 0.6768410852713178\n",
      "F1-score: 0.6751974528284977\n",
      "Precision Score:  0.6766519213325874\n",
      "Recall Score: 0.6768410852713178\n",
      "\n",
      "RESULTADOS Random Forest:\n",
      "\n",
      "Accuracy Score: 0.9215654608096469\n",
      "F1-score: 0.9215242530076392\n",
      "Precision Score:  0.9218204903571169\n",
      "Recall Score: 0.9215654608096469\n",
      "\n",
      "RESULTADOS Random Forest:\n",
      "\n",
      "Accuracy Score: 0.7037575366063739\n",
      "F1-score: 0.7038775368622544\n",
      "Precision Score:  0.7041015747256649\n",
      "Recall Score: 0.7037575366063739\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRESULTADOS K_nearest neighbors:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, y_pred_knn)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, y_pred_knn,average=\"weighted\")))\n",
    "print(\"Precision Score: \",precision_score(y_test,y_pred_knn,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score:\" , recall_score(y_test, y_pred_knn, pos_label='positive',average=\"weighted\"))\n",
    "\n",
    "print(\"\\nRESULTADOS Random Forest:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, y_pred_rnd)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, y_pred_rnd,average=\"weighted\")))\n",
    "print(\"Precision Score: \",precision_score(y_test,y_pred_rnd,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score:\" , recall_score(y_test, y_pred_rnd, pos_label='positive',average=\"weighted\"))\n",
    "\n",
    "print(\"\\nRESULTADOS Random Forest:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, y_pred_dtc)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, y_pred_dtc,average=\"weighted\")))\n",
    "print(\"Precision Score: \",precision_score(y_test,y_pred_dtc,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score:\" , recall_score(y_test, y_pred_dtc, pos_label='positive',average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras predecir los modelos individualmente, vamos a realizar el Voting para ver si mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS HARD VOTING:\n",
      "\n",
      "Accuracy Score: 0.733634797588286\n",
      "F1-score: 0.7329673350163669\n",
      "Precision Score :  0.7345057344017085\n",
      "Recall Score : 0.733634797588286\n",
      "\n",
      "RESULTADOS SOFT VOTING:\n",
      "\n",
      "Accuracy Score: 0.7257213608957795\n",
      "F1-score: 0.7252095804497332\n",
      "Precision Score:  0.7258844055194951\n",
      "Recall Score: 0.7257213608957795\n"
     ]
    }
   ],
   "source": [
    "#Creo ensemble de Votación Hard\n",
    "vot_clf_h = VotingClassifier(estimators = [('dtc', dtc_clf), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'hard')\n",
    "\n",
    "#Creo ensemble de Votación Soft\n",
    "vot_clf_s = VotingClassifier(estimators = [('dtc', dtc_clf), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'soft')\n",
    "\n",
    "\n",
    "#Entreno ambos ensembles\n",
    "vot_clf_h.fit(x_train, y_train)\n",
    "vot_clf_s.fit(x_train, y_train)\n",
    "\n",
    "#Evaluo en conjunto de test\n",
    "pred_h = vot_clf_h.predict(x_test)\n",
    "pred_s = vot_clf_s.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "#Calculo accuracy\n",
    "print(\"RESULTADOS HARD VOTING:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, pred_h)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, pred_h,average=\"weighted\")))\n",
    "print(\"Precision Score : \",precision_score(y_test,pred_h,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score :\" , recall_score(y_test, pred_h, pos_label='positive',average=\"weighted\"))\n",
    "\n",
    "print(\"\\nRESULTADOS SOFT VOTING:\\n\")\n",
    "print('Accuracy Score: {}'.format(accuracy_score(y_test, pred_s)))\n",
    "print('F1-score: {}'.format(f1_score(y_test, pred_s,average=\"weighted\")))\n",
    "print(\"Precision Score: \",precision_score(y_test,pred_s,pos_label='positive',average=\"weighted\"))\n",
    "print(\"Recall Score:\" , recall_score(y_test, pred_s, pos_label='positive',average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluimos que conviene utilizar el metodo de Hard voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver tras comparar los dos modelos, nos da una metrica superior el Voting realizado con los modelos del TP1. Esto se debe a que dichos modelos fueron ajustados de mejor manera y son mas precisos. Sin embargo, algo que nos llamo la atención es que los modelos de Random Forest obtienen mejores resultados que el propio Voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecciono variables regresoras y a predecir\n",
    "x_train = viviendas_train[['latitud','longitud', 'property_surface_total', 'property_surface_covered']]\n",
    "x_test = viviendas_test[['latitud','longitud', 'property_surface_total', 'property_surface_covered']]\n",
    "\n",
    "y_train = viviendas_train.property_price\n",
    "y_test = viviendas_test.property_price\n",
    "\n",
    "#Normalizo\n",
    "scaler = MinMaxScaler() \n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos Stacking con modelos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo los modelos\n",
    "knn_n = KNeighborsRegressor()\n",
    "gbr_n = GradientBoostingRegressor()\n",
    "xgboost_n = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    " \n",
    " # define the base models\n",
    " level0 = list()\n",
    " level0.append(('knn', knn_n)) \n",
    " level0.append(('xgboost', xgboost_n)) \n",
    " level0.append(('gbr', gbr_n)) \n",
    "\n",
    " # define meta learner model\n",
    " level1 = LinearRegression()\n",
    "\n",
    " # define the stacking ensemble\n",
    " model = StackingRegressor(estimators=level0, \n",
    "                                    final_estimator=level1, \n",
    "                                    passthrough=True, \n",
    "                                    cv=5,\n",
    "                                    verbose=2)\n",
    " \n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "\n",
    "def get_models():\n",
    " models = dict()\n",
    " models['knn'] = knn_n\n",
    " models['xgb'] = xgboost_n\n",
    " models['gbr'] = gbr_n\n",
    " models['stacking'] = get_stacking()\n",
    "\n",
    " return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para plotear a performance\n",
    "def plot_results(model_scores, name):\n",
    "    \n",
    "    model_names = list(model_scores.keys())\n",
    "    results = [model_scores[model] for model in model_names]\n",
    "    fig = go.Figure()\n",
    "    for model, result in zip(model_names, results):\n",
    "        fig.add_trace(go.Box(\n",
    "            y=result,\n",
    "            name=model,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            marker_size=2,\n",
    "            line_width=1)\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title='Performance of Different Models Using 5-Fold Cross-Validation',\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Accuracy',\n",
    "    showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_metricas_regresion(target_test, precios_predichos):\n",
    "    # Mean Square Error\n",
    "    mse = metrics.mean_squared_error(\n",
    "        y_true=target_test, y_pred=precios_predichos, squared=True\n",
    "    )\n",
    "\n",
    "    print(f\"El error (mse) de test es: {mse}\")\n",
    "\n",
    "    # Root Mean Square Error\n",
    "    rmse = metrics.mean_squared_error(\n",
    "        y_true=target_test, y_pred=precios_predichos, squared=False\n",
    "    )\n",
    "\n",
    "    print(f\"El error (rmse) de test es: {rmse}\")\n",
    "\n",
    "    r2 = metrics.r2_score(target_test, precios_predichos)\n",
    "    print(f\"El score R2 es: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = get_stacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(cv=5,\n",
       "                  estimators=[(&#x27;knn&#x27;, KNeighborsRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            i...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                              (&#x27;gbr&#x27;, GradientBoostingRegressor())],\n",
       "                  final_estimator=LinearRegression(), passthrough=True,\n",
       "                  verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(cv=5,\n",
       "                  estimators=[(&#x27;knn&#x27;, KNeighborsRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            i...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                              (&#x27;gbr&#x27;, GradientBoostingRegressor())],\n",
       "                  final_estimator=LinearRegression(), passthrough=True,\n",
       "                  verbose=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(cv=5,\n",
       "                  estimators=[('knn', KNeighborsRegressor()),\n",
       "                              ('xgboost',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            i...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...)),\n",
       "                              ('gbr', GradientBoostingRegressor())],\n",
       "                  final_estimator=LinearRegression(), passthrough=True,\n",
       "                  verbose=2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./Models/stacking_modelos_nuevos']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "stacking.fit(x_train, y_train)\n",
    "joblib.dump(stacking, './Models/stacking_modelos_nuevos')\"\"\"\n",
    "\n",
    "stacking = joblib.load('./Models/stacking_modelos_nuevos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Regressor:\n",
      "El error (mse) de test es: 11821616533.516012\n",
      "El error (rmse) de test es: 108727.25754619221\n",
      "El score R2 es: 0.873594814426625\n",
      "\n",
      "XGBoost Regressor:\n",
      "El error (mse) de test es: 10919589772.080612\n",
      "El error (rmse) de test es: 104496.84096699102\n",
      "El score R2 es: 0.8832399302065291\n",
      "\n",
      "Gradient Boosting Regressor:\n",
      "El error (mse) de test es: 14184599327.20136\n",
      "El error (rmse) de test es: 119099.11556011389\n",
      "El score R2 es: 0.8483281110366402\n"
     ]
    }
   ],
   "source": [
    "#Evaluo las metricas de los modelos por individual\n",
    "\n",
    "print(\"\\nKNN Regressor:\")\n",
    "knn_f = knn_n.fit(x_train, y_train)\n",
    "y_pred = knn_f.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)\n",
    "\n",
    "print(\"\\nXGBoost Regressor:\")\n",
    "xgboost_f = xgboost_n.fit(x_train, y_train)\n",
    "y_pred = xgboost_f.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "gbr_f = gbr_n.fit(x_train, y_train)\n",
    "y_pred = gbr_f.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error (mse) de test es: 9946147391.381863\n",
      "El error (rmse) de test es: 99730.37346456626\n",
      "El score R2 es: 0.893648672904988\n"
     ]
    }
   ],
   "source": [
    "#Evaluo el Stacking de los modelos\n",
    "\n",
    "y_pred = stacking.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como las metricas por separado son inferiores al Stacking. Esto nos demuestra que nuestro modelo esta bien hecho y conviene utilizar el Stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos Stacking con nuestros modelos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:13:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importo los modelos del TP1\n",
    "\n",
    "gbr = joblib.load('./TP1/Models/rand_GBR')\n",
    "knn = joblib.load('./TP1/Models/rand_knn')\n",
    "xgboost = joblib.load('./TP1/Models/rand_xgb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    " \n",
    " # define the base models\n",
    " level0 = list()\n",
    " level0.append(('knn', knn )) \n",
    " level0.append(('xgboost', xgboost )) \n",
    " level0.append(('gbr', gbr)) \n",
    "\n",
    " # define meta learner model\n",
    " level1 = LinearRegression()\n",
    "\n",
    " # define the stacking ensemble\n",
    " model = StackingRegressor(estimators=level0, \n",
    "                                    final_estimator=level1, \n",
    "                                    passthrough=True, \n",
    "                                    cv=5,\n",
    "                                    verbose=2)\n",
    " \n",
    "\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "\n",
    "def get_models():\n",
    " models = dict()\n",
    " models['knn'] = knn \n",
    " models['xgb'] = xgboost \n",
    " models['gbr'] = gbr \n",
    " models['stacking'] = get_stacking()\n",
    "\n",
    " return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para plotear a performance\n",
    "def plot_results(model_scores, name):\n",
    "    \n",
    "    model_names = list(model_scores.keys())\n",
    "    results = [model_scores[model] for model in model_names]\n",
    "    fig = go.Figure()\n",
    "    for model, result in zip(model_names, results):\n",
    "        fig.add_trace(go.Box(\n",
    "            y=result,\n",
    "            name=model,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            marker_size=2,\n",
    "            line_width=1)\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title='Performance of Different Models Using 5-Fold Cross-Validation',\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Accuracy',\n",
    "    showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_metricas_regresion(target_test, precios_predichos):\n",
    "    # Mean Square Error\n",
    "    mse = metrics.mean_squared_error(\n",
    "        y_true=target_test, y_pred=precios_predichos, squared=True\n",
    "    )\n",
    "\n",
    "    print(f\"El error (mse) de test es: {mse}\")\n",
    "\n",
    "    # Root Mean Square Error\n",
    "    rmse = metrics.mean_squared_error(\n",
    "        y_true=target_test, y_pred=precios_predichos, squared=False\n",
    "    )\n",
    "\n",
    "    print(f\"El error (rmse) de test es: {rmse}\")\n",
    "\n",
    "    r2 = metrics.r2_score(target_test, precios_predichos)\n",
    "    print(f\"El score R2 es: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = get_stacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[00:58:58] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "stacking.fit(x_train, y_train)\n",
    "joblib.dump(stacking, './Models/stacking_modelos_tp1')\n",
    "\"\"\"\n",
    "stacking = joblib.load('./Models/stacking_modelos_tp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Regressor:\n",
      "El error (mse) de test es: 9903379174.372705\n",
      "El error (rmse) de test es: 99515.72325202035\n",
      "El score R2 es: 0.894105981293596\n",
      "\n",
      "XGBoost Regressor:\n",
      "El error (mse) de test es: 9683927892.144327\n",
      "El error (rmse) de test es: 98406.95042599546\n",
      "El score R2 es: 0.8964525114805418\n",
      "\n",
      "Gradient Boosting Regressor:\n",
      "El error (mse) de test es: 8607454252.030666\n",
      "El error (rmse) de test es: 92776.36688311666\n",
      "El score R2 es: 0.9079629381516854\n"
     ]
    }
   ],
   "source": [
    "#Evaluo las metricas de los modelos por individual\n",
    "\n",
    "print(\"\\nKNN Regressor:\")\n",
    "y_pred = knn.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)\n",
    "\n",
    "print(\"\\nXGBoost Regressor:\")\n",
    "y_pred = xgboost.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)\n",
    "\n",
    "y_pred = gbr.predict(x_test)\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "imprimir_metricas_regresion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error (mse) de test es: 8398373997.479234\n",
      "El error (rmse) de test es: 91642.64289881231\n",
      "El score R2 es: 0.910198573887405\n"
     ]
    }
   ],
   "source": [
    "#Evaluo el Stacking de los modelos\n",
    "\n",
    "y_pred = stacking.predict(x_test)\n",
    "imprimir_metricas_regresion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como las metricas por separado son inferiores al Stacking. Esto nos demuestra que nuestro modelo esta bien hecho y conviene utilizar el Stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar en los dos modelos planteados, obtenemos que el segundo modelo es el mas preciso. Esto es lo mas lógico ya que es un modelo el cual utiliza modelos de regresión creados especificamente en el TP1, mientras que el otro son modelos creados de cero sin ninguna especificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8e076f4d6cc96beb144640363c4536da3507f682d6c05a936aea27f47bf2151"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
